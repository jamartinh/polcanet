{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **P**rincipal **O**rthogonal **L**atent **C**omponents **A**nalysis Net (POLCA-Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T20:24:29.264294Z",
     "start_time": "2024-07-05T20:24:29.244120Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T20:24:35.998606Z",
     "start_time": "2024-07-05T20:24:34.618817Z"
    }
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-paper\")\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "from sklearn import datasets, decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T20:24:37.082692Z",
     "start_time": "2024-07-05T20:24:37.045050Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from polcanet import LinearDecoder, PolcaNet\n",
    "from polcanet.example_aencoders import (\n",
    "    MinMaxScalerTorch,\n",
    "    StandardScalerTorch,\n",
    "    autoencoder_factory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T20:24:37.082692Z",
     "start_time": "2024-07-05T20:24:37.045050Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from polcanet.polcanet_reports import (\n",
    "    analyze_latent_feature_importance,\n",
    "    analyze_latent_space,\n",
    "    analyze_reconstruction_error,\n",
    "    linearity_tests_analysis,   \n",
    "    orthogonality_test_analysis,\n",
    "    plot_cumsum_variance,\n",
    "    plot_scatter_corr_matrix,\n",
    "    plot_stdev_pct,\n",
    "    show_correlation_matrix,\n",
    "    variance_test_analysis,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T20:24:38.074048Z",
     "start_time": "2024-07-05T20:24:38.049875Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T20:24:38.862979Z",
     "start_time": "2024-07-05T20:24:38.839943Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.profiler.emit_nvtx at 0x7f07517b5a60>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(False)\n",
    "torch.autograd.profiler.profile(False)\n",
    "torch.autograd.profiler.emit_nvtx(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "\n",
    "datasets.MNIST\n",
    "mnist_trainset = datasets.MNIST(root=\"../../data\", train=True, download=True, transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50000, 1, 28, 28]),\n",
       " torch.Size([10000, 1, 28, 28]),\n",
       " (50000, 28, 28),\n",
       " (50000,),\n",
       " (10000,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = mnist_trainset.data[:-10000].reshape(-1, 1, 28, 28) / 255.0\n",
    "eval_dataset = mnist_trainset.data[-10000:].reshape(-1, 1, 28, 28) / 255.0\n",
    "y_train = mnist_trainset.targets[:-10000].numpy()\n",
    "y_test = mnist_trainset.targets[-10000:].numpy()\n",
    "X = np.array(train_dataset.numpy(), dtype=np.float32)\n",
    "X = np.squeeze(X)\n",
    "train_dataset.shape, eval_dataset.shape, X.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Fit standard sklearn PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T20:24:42.736209Z",
     "start_time": "2024-07-05T20:24:42.710916Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09744108, 0.07060017, 0.06216173, 0.05379298, 0.04857272,\n",
       "       0.04319709, 0.03277376, 0.0288645 , 0.02768748, 0.02365975,\n",
       "       0.02099563, 0.02020426, 0.01715833, 0.01681817, 0.01579296,\n",
       "       0.0149279 , 0.01318197, 0.01276548, 0.01186538, 0.01151048,\n",
       "       0.01069133, 0.01007524, 0.00953653, 0.0090788 , 0.00882809,\n",
       "       0.00836969, 0.00817559, 0.00784815], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = decomposition.PCA(n_components=28)\n",
    "pca.fit(np.squeeze(X.reshape(X.shape[0], -1)))\n",
    "Xpca = pca.transform(X.reshape(X.shape[0], -1))\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Fit POLCANet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T20:24:44.401718Z",
     "start_time": "2024-07-05T20:24:44.313568Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolcaNet(\n",
       "  (encoder): ConvAutoencoder(\n",
       "    (encoder): Sequential(\n",
       "      (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): SiLU()\n",
       "      (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (3): SiLU()\n",
       "      (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (5): SiLU()\n",
       "      (6): Conv2d(64, 28, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (7): SiLU()\n",
       "      (8): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "  )\n",
       "  (decoder): LinearDecoder(\n",
       "    (decoder): Sequential(\n",
       "      (0): Linear(in_features=112, out_features=1024, bias=True)\n",
       "      (1): NoActivation()\n",
       "      (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (3): NoActivation()\n",
       "      (4): Linear(in_features=1024, out_features=784, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (polcanet_loss): PolcaNetLoss()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = X[0].shape[0]\n",
    "M = X[0].shape[1]\n",
    "\n",
    "ae_input = X\n",
    "act_fn = torch.nn.SiLU\n",
    "input_dim = ae_input[0].shape\n",
    "latent_dim = 28\n",
    "assert N == input_dim[0], \"input_dim[0] should match first matrix dimension N\"\n",
    "assert M == input_dim[1], \"input_dim[1] should match second matrix dimension M\"\n",
    "\n",
    "encoder_conv = autoencoder_factory(\n",
    "    seq_len=input_dim[0],  #    N\n",
    "    input_dim=input_dim[1],  #  M\n",
    "    latent_dim=latent_dim,\n",
    "    hidden_dim=None,\n",
    "    num_layers=None,\n",
    "    autoencoder_type=\"conv2d\",\n",
    "    act_fn=act_fn,\n",
    ")\n",
    "\n",
    "decoder_conv = LinearDecoder(latent_dim=latent_dim * 4, input_dim=input_dim, hidden_dim=1024, num_layers=3)\n",
    "\n",
    "model = PolcaNet(\n",
    "    encoder=encoder_conv,\n",
    "    decoder=decoder_conv,\n",
    "    latent_dim=latent_dim * 4,\n",
    "    alpha=0.1,  # ortgogonality loss\n",
    "    beta=1.0,  # variance sorting loss\n",
    "    gamma=1.0,  # variance reduction loss\n",
    "    device=\"cuda:3\",\n",
    "    # scaler = StandardScalerTorch(),\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T20:25:16.617814Z",
     "start_time": "2024-07-05T20:24:45.488325Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2deb2b096fc243ec9ee311f9b8887f38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.to(\"cuda:1\")\n",
    "model.train_model(data=X, batch_size=512, num_epochs=10000, report_freq=100, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T20:25:46.131475Z",
     "start_time": "2024-07-05T20:25:16.619408Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model.train_model(data=X, batch_size=512, num_epochs=1000, report_freq=100, lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T20:25:46.131475Z",
     "start_time": "2024-07-05T20:25:16.619408Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model.train_model(data=X, batch_size=512, num_epochs=1000, report_freq=100, lr=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T21:06:02.858038Z",
     "start_time": "2024-07-05T21:06:02.832778Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "analyze_reconstruction_error(model, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T21:06:02.858038Z",
     "start_time": "2024-07-05T21:06:02.832778Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "latents, reconstructed = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T21:06:03.848230Z",
     "start_time": "2024-07-05T21:06:03.822048Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "analyze_latent_space(model, latents=latents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T20:27:13.761017Z",
     "start_time": "2024-07-05T20:27:13.732856Z"
    }
   },
   "outputs": [],
   "source": [
    "orthogonality_test_analysis(model, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T20:27:13.761017Z",
     "start_time": "2024-07-05T20:27:13.732856Z"
    }
   },
   "outputs": [],
   "source": [
    "variance_test_analysis(model, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T20:27:13.761017Z",
     "start_time": "2024-07-05T20:27:13.732856Z"
    }
   },
   "outputs": [],
   "source": [
    "linearity_tests_analysis(model, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T21:06:11.314832Z",
     "start_time": "2024-07-05T21:06:11.137234Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_cumsum_variance(model, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T21:06:15.610838Z",
     "start_time": "2024-07-05T21:06:15.585880Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot2d_analysis(X, y, title, legend=True):\n",
    "    fig = plt.figure(1, figsize=(5, 5))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    for label in range(10):\n",
    "        ax.scatter(X[y == label, 0], X[y == label, 1], label=label)\n",
    "        ax.set_xlabel(\"component: 0\")\n",
    "        ax.set_ylabel(\"component 1\")\n",
    "    if legend:\n",
    "        plt.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T21:06:18.073238Z",
     "start_time": "2024-07-05T21:06:17.757219Z"
    }
   },
   "outputs": [],
   "source": [
    "o1 = widgets.Output()\n",
    "o2 = widgets.Output()\n",
    "with o1:\n",
    "    _, _ = plot2d_analysis(Xpca, y_train, title=\"PCA transform\", legend=True)\n",
    "with o2:\n",
    "    _, _ = plot2d_analysis(latents, y_train, title=\"POLCA-Net latent\")\n",
    "layout = widgets.Layout(grid_template_columns=\"repeat(2, 600px)\")\n",
    "accordion = widgets.GridBox(children=[o1, o2], layout=layout)\n",
    "display(accordion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T21:06:36.799237Z",
     "start_time": "2024-07-05T21:06:36.307747Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "o1 = widgets.Output()\n",
    "o2 = widgets.Output()\n",
    "o3 = widgets.Output()\n",
    "o4 = widgets.Output()\n",
    "\n",
    "with o1:\n",
    "    fig1, ax1 = plot2d_analysis(X, y_train, \"Original data two first componets\", legend=False)\n",
    "\n",
    "with o2:\n",
    "    latents, reconstructed = model.predict(X)\n",
    "    fig2, ax2 = plot2d_analysis(np.round(reconstructed, 1), y_train, title=\"Reconstructed with POLCA all componets\", legend=False)\n",
    "\n",
    "with o3:\n",
    "    latents, reconstructed = model.predict(X)\n",
    "    fig3, ax3 = plot2d_analysis(np.round(reconstructed, 1), y_train, title=\"Reconstructed with POLCA two componets\", legend=False)\n",
    "\n",
    "with o4:\n",
    "    fig4, ax4 = plot2d_analysis(np.round(pca.inverse_transform(Xpca), 1), y_train, \"Reconstructed with PCA two componets\", legend=False)\n",
    "\n",
    "\n",
    "layout = widgets.Layout(grid_template_columns=\"repeat(2, 450px)\")\n",
    "accordion = widgets.GridBox(children=[o1, o2, o3, o4], layout=layout)\n",
    "display(accordion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T21:06:40.553393Z",
     "start_time": "2024-07-05T21:06:40.426319Z"
    }
   },
   "outputs": [],
   "source": [
    "latents, reconstructed = model.predict(X)\n",
    "vectors = []\n",
    "labels = [str(i) for i in range(10)]\n",
    "for c, label in enumerate(labels):\n",
    "    vectors.append(np.sum(latents[y_train == c, :], axis=1))\n",
    "\n",
    "\n",
    "plt.boxplot(vectors, tick_labels=labels)\n",
    "plt.violinplot(vectors, showmeans=False, showmedians=True)\n",
    "plt.suptitle(\"Polca Analysis of the summation of latent orthogonal components\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T21:06:45.532569Z",
     "start_time": "2024-07-05T21:06:45.019812Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "o1 = widgets.Output()\n",
    "o2 = widgets.Output()\n",
    "\n",
    "\n",
    "with o1:\n",
    "    scores = model.score(X)\n",
    "    sns.displot(scores, kde=True)\n",
    "    plt.title(\"Last component with clean data\")\n",
    "    plt.show()\n",
    "\n",
    "with o2:\n",
    "    scores = model.score(X * (np.random.random(size=X.shape) - 0.5) * 1)\n",
    "    sns.displot(scores, kde=True)\n",
    "    plt.title(\"Last componet with uniform noise in data\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "layout = widgets.Layout(grid_template_columns=\"repeat(2, 500px)\")\n",
    "accordion = widgets.GridBox(children=[o1, o2], layout=layout)\n",
    "display(accordion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T20:26:50.830968Z",
     "start_time": "2024-07-05T20:26:50.805485Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.std_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T20:26:51.683268Z",
     "start_time": "2024-07-05T20:26:51.659806Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.mean_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Classification with two components on PCA vs POLCA Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ttest_rel\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, RidgeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import minmax_scale, scale\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_train, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca = pca.transform(X_train.reshape(X_train.shape[0], -1))\n",
    "X_test_pca = pca.transform(X_test.reshape(X_test.shape[0], -1))\n",
    "X_train_pca.shape, X_test_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data using POLCA-Net\n",
    "# X_train_polca = model.predict(X_train,np.array([1, 1, 0, 0]))[0][:,:2]\n",
    "X_train_polca = model.predict(X_train)[0][:, :8]\n",
    "# X_test_polca = model.predict(X_test, np.array([1, 1, 0, 0]))[0][:,:2]\n",
    "X_test_polca = model.predict(X_test)[0][:, :8]\n",
    "X_train_polca.shape, X_test_polca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classifiers\n",
    "classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "    \"Linear SVM\": SVC(kernel=\"linear\", probability=True),\n",
    "    \"Ridge Classifier\": RidgeClassifier(),\n",
    "    \"Perceptron\": Perceptron(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate classifiers on both PCA and POLCA-Net transformed datasets\n",
    "results = []\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    # Train on PCA\n",
    "    clf.fit(minmax_scale(X_train_pca), y_train)\n",
    "    y_pred_pca = clf.predict(minmax_scale(X_test_pca))\n",
    "    accuracy_pca = accuracy_score(y_test, y_pred_pca)\n",
    "    report_pca = classification_report(y_test, y_pred_pca, output_dict=True)\n",
    "    cm_pca = confusion_matrix(y_test, y_pred_pca)\n",
    "\n",
    "    # Train on POLCA-Net\n",
    "    clf.fit(minmax_scale(X_train_polca), y_train)\n",
    "    y_pred_polca = clf.predict(minmax_scale(X_test_polca))\n",
    "    accuracy_polca = accuracy_score(y_test, y_pred_polca)\n",
    "    report_polca = classification_report(y_test, y_pred_polca, output_dict=True)\n",
    "    cm_polca = confusion_matrix(y_test, y_pred_polca)\n",
    "\n",
    "    # Append results\n",
    "    results.append(\n",
    "        {\n",
    "            \"Classifier\": name,\n",
    "            \"Transformation\": \"PCA\",\n",
    "            \"Accuracy\": accuracy_pca,\n",
    "            \"Precision\": report_pca[\"weighted avg\"][\"precision\"],\n",
    "            \"Recall\": report_pca[\"weighted avg\"][\"recall\"],\n",
    "            \"F1-Score\": report_pca[\"weighted avg\"][\"f1-score\"],\n",
    "            \"Confusion Matrix\": cm_pca,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    results.append(\n",
    "        {\n",
    "            \"Classifier\": name,\n",
    "            \"Transformation\": \"POLCA-Net\",\n",
    "            \"Accuracy\": accuracy_polca,\n",
    "            \"Precision\": report_polca[\"weighted avg\"][\"precision\"],\n",
    "            \"Recall\": report_polca[\"weighted avg\"][\"recall\"],\n",
    "            \"F1-Score\": report_polca[\"weighted avg\"][\"f1-score\"],\n",
    "            \"Confusion Matrix\": cm_polca,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to display the results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display the main metrics table\n",
    "main_metrics_df = results_df.drop(columns=[\"Confusion Matrix\"])\n",
    "main_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical test: Paired t-test for accuracies\n",
    "pca_accuracies = results_df[results_df[\"Transformation\"] == \"PCA\"][\"F1-Score\"]\n",
    "polca_accuracies = results_df[results_df[\"Transformation\"] == \"POLCA-Net\"][\"F1-Score\"]\n",
    "\n",
    "t_stat, p_value = ttest_rel(pca_accuracies.values, polca_accuracies.values)\n",
    "\n",
    "print(f\"\\nPaired t-test results: t-statistic = {t_stat}, p-value = {p_value}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a statistically significant difference between the PCA and POLCA-Net transformations.\")\n",
    "else:\n",
    "    print(\"There is no statistically significant difference between the PCA and POLCA-Net transformations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "# Plot PCA\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_test_pca[:, 0], X_test_pca[:, 1], c=y_test, cmap=\"viridis\", edgecolor=\"k\", s=50)\n",
    "plt.title(\"PCA: Iris Test Set\")\n",
    "plt.xlabel(\"Component 1\")\n",
    "plt.ylabel(\"Component 2\")\n",
    "\n",
    "# Plot POLCA-Net\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X_test_polca[:, 0], X_test_polca[:, 1], c=y_test, cmap=\"viridis\", edgecolor=\"k\", s=50)\n",
    "plt.title(\"POLCA-Net: Iris Test Set\")\n",
    "plt.xlabel(\"Component 1\")\n",
    "plt.ylabel(\"Component 2\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Plot Confusion Matrices for each classifier\n",
    "fig, axes = plt.subplots(len(classifiers), 2, figsize=(10, 20))\n",
    "\n",
    "for i, (name, clf) in enumerate(classifiers.items()):\n",
    "    # PCA Confusion Matrix\n",
    "    cm_pca = results_df[(results_df[\"Classifier\"] == name) & (results_df[\"Transformation\"] == \"PCA\")][\"Confusion Matrix\"].values[0]\n",
    "    axes[i, 0].imshow(cm_pca, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "    axes[i, 0].set_title(f\"{name} Confusion Matrix - PCA\")\n",
    "    axes[i, 0].set_xlabel(\"Predicted label\")\n",
    "    axes[i, 0].set_ylabel(\"True label\")\n",
    "\n",
    "    # POLCA-Net Confusion Matrix\n",
    "    cm_polca = results_df[(results_df[\"Classifier\"] == name) & (results_df[\"Transformation\"] == \"POLCA-Net\")][\"Confusion Matrix\"].values[0]\n",
    "    axes[i, 1].imshow(cm_polca, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "    axes[i, 1].set_title(f\"{name} Confusion Matrix - POLCA-Net\")\n",
    "    axes[i, 1].set_xlabel(\"Predicted label\")\n",
    "    axes[i, 1].set_ylabel(\"True label\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "95022f601a219c6b6d093149c9a9b9a061a4446d3680d89cef8a1f82970031f2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
