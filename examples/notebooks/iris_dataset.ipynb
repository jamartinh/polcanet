{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d868c211-777b-4754-acd8-a91fcf4e2b3d",
   "metadata": {},
   "source": [
    "# **P**rincipal **O**rthogonal **L**atent **C**omponents **A**nalysis Net (POLCA-Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "972b1500e58ca5ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T20:24:29.264294Z",
     "start_time": "2024-07-05T20:24:29.244120Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12e032801a73fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "import seaborn\n",
    "\n",
    "plt.style.use([\"science\", \"no-latex\"])\n",
    "\n",
    "# Query the current default figure size\n",
    "current_fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "print(f\"Current default figure size: {current_fig_size}\")\n",
    "\n",
    "# Define a scalar factor\n",
    "scalar_factor = 1.5\n",
    "\n",
    "# Multiply the current figure size by the scalar factor\n",
    "new_fig_size = [size * scalar_factor for size in current_fig_size]\n",
    "\n",
    "# Set the new default figure size\n",
    "plt.rcParams[\"figure.figsize\"] = new_fig_size\n",
    "\n",
    "print(f\"New default figure size: {new_fig_size}\")\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn import datasets, decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a353256943211846",
   "metadata": {},
   "outputs": [],
   "source": [
    "from polcanet import LinearDecoder, PolcaNet\n",
    "from polcanet.aencoders import (\n",
    "    DenseEncoder,\n",
    "    MinMaxScalerTorch,\n",
    "    StandardScalerTorch,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d573cafcda65c1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polcanet.reports as report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd32889664347666",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6691bef5056d5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.autograd.set_detect_anomaly(False)\n",
    "torch.autograd.profiler.profile(False)\n",
    "torch.autograd.profiler.emit_nvtx(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6230ec0646a6da3",
   "metadata": {},
   "source": [
    "### Load iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e584b797f89434a",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X.shape, X[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f589d15387af22eb",
   "metadata": {},
   "source": [
    "### Fit standard sklearn PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e2f229d550ff8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = decomposition.PCA(n_components=2)\n",
    "pca.fit(X)\n",
    "Xpca = pca.transform(X)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee368b75f0ea172b",
   "metadata": {},
   "source": [
    "### Fit POLCANet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0aea2e1164dcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_input = X\n",
    "act_fn = torch.nn.SiLU\n",
    "input_dim = (ae_input.shape[1],)\n",
    "latent_dim = 4\n",
    "\n",
    "encoder_iris = DenseEncoder(\n",
    "    input_dim=input_dim,\n",
    "    latent_dim=latent_dim,\n",
    "    num_layers=5,\n",
    "    act_fn=act_fn,\n",
    "    first_layer_size= 256,\n",
    "    # hidden_size=256,\n",
    ")\n",
    "\n",
    "decoder_iris = LinearDecoder(\n",
    "    latent_dim=latent_dim,\n",
    "    input_dim=input_dim,\n",
    "    hidden_dim=256,\n",
    "    num_layers=3,\n",
    "    act_fn=torch.nn.Tanh,\n",
    ")\n",
    "\n",
    "\n",
    "model_iris = PolcaNet(\n",
    "    encoder=encoder_iris,\n",
    "    decoder=decoder_iris,\n",
    "    latent_dim=latent_dim,\n",
    "    alpha=0.1,  # ortgogonality loss\n",
    "    beta=1.0,  # variance sorting loss\n",
    "    gamma=1.0,  # variance reduction loss\n",
    "    device=\"cuda\",\n",
    "    # scaler = StandardScalerTorch(),\n",
    ")\n",
    "model_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d61feb1adf51325",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_iris.to(\"cuda\")\n",
    "model_iris.train_model(\n",
    "    data=X, batch_size=512, num_epochs=10000, report_freq=100, lr=1e-3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af52c7643cb0a5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_iris.train_model(\n",
    "    data=X, batch_size=512, num_epochs=10000, report_freq=100, lr=1e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b420e0bb11023d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_iris.train_model(\n",
    "    data=X, batch_size=512, num_epochs=10000, report_freq=100, lr=1e-5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac938c16ea7531d",
   "metadata": {},
   "source": [
    "## Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3638bed6e261730f",
   "metadata": {},
   "outputs": [],
   "source": [
    "report.analyze_reconstruction_error(model_iris, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cd2ae58785e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "latents, reconstructed = model_iris.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19952634790ba67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "report.analyze_latent_space(model_iris, latents=latents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c12c4538756efcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "report.orthogonality_test_analysis(model_iris, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612ae90e78b7e9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "report.variance_test_analysis(model_iris, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3296456774ed164e",
   "metadata": {},
   "outputs": [],
   "source": [
    "report.linearity_tests_analysis(model_iris, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d771734c5946f747",
   "metadata": {},
   "source": [
    "## Polca Net vs. PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da68685e3c85542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot2d_analysis(X, y, title, legend=True):\n",
    "    fig = plt.figure(1, figsize=(5, 5))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    for name, label in [(\"Setosa\", 0), (\"Versicolour\", 1), (\"Virginica\", 2)]:\n",
    "        ax.scatter(X[y == label, 0], X[y == label, 1], label=name)\n",
    "        ax.set_xlabel(\"component 0\")\n",
    "        ax.set_ylabel(\"component 1\")\n",
    "    if legend:\n",
    "        plt.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd6701414fb4057",
   "metadata": {},
   "outputs": [],
   "source": [
    "o1 = widgets.Output()\n",
    "o2 = widgets.Output()\n",
    "with o1:\n",
    "    _, _ = plot2d_analysis(Xpca, y, title=\"PCA transform\", legend=True)\n",
    "with o2:\n",
    "    _, _ = plot2d_analysis(latents, y, title=\"POLCA-Net latent\")\n",
    "layout = widgets.Layout(grid_template_columns=\"repeat(2, 600px)\")\n",
    "accordion = widgets.GridBox(children=[o1, o2], layout=layout)\n",
    "display(accordion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4a23f5915874a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "o1 = widgets.Output()\n",
    "o2 = widgets.Output()\n",
    "o3 = widgets.Output()\n",
    "o4 = widgets.Output()\n",
    "\n",
    "with o1:\n",
    "    fig1, ax1 = plot2d_analysis(X, y, \"Original data two first componets\", legend=False)\n",
    "\n",
    "with o2:\n",
    "    latents, reconstructed = model_iris.predict(X, np.ones(latent_dim))\n",
    "    fig2, ax2 = plot2d_analysis(\n",
    "        np.round(reconstructed, 1),\n",
    "        y,\n",
    "        title=\"Reconstructed with POLCA all componets\",\n",
    "        legend=False,\n",
    "    )\n",
    "\n",
    "with o3:\n",
    "    latents, reconstructed = model_iris.predict(X, np.array([1, 1, 0, 0]))\n",
    "    fig3, ax3 = plot2d_analysis(\n",
    "        np.round(reconstructed, 1),\n",
    "        y,\n",
    "        title=\"Reconstructed with POLCA two componets\",\n",
    "        legend=False,\n",
    "    )\n",
    "\n",
    "with o4:\n",
    "    fig4, ax4 = plot2d_analysis(\n",
    "        np.round(pca.inverse_transform(Xpca), 1),\n",
    "        y,\n",
    "        \"Reconstructed with PCA two componets\",\n",
    "        legend=False,\n",
    "    )\n",
    "\n",
    "\n",
    "layout = widgets.Layout(grid_template_columns=\"repeat(2, 450px)\")\n",
    "accordion = widgets.GridBox(children=[o1, o2, o3, o4], layout=layout)\n",
    "display(accordion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7a4403cde44d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "latents, reconstructed = model_iris.predict(X)\n",
    "vectors = []\n",
    "labels = [\"Setosa\", \"Versicolour\", \"Virginica\"]\n",
    "for c, label in enumerate(labels):\n",
    "    vectors.append(np.sum(latents[y == c, :], axis=1))\n",
    "\n",
    "\n",
    "plt.boxplot(vectors, tick_labels=labels)\n",
    "plt.violinplot(vectors, showmeans=False, showmedians=True)\n",
    "plt.suptitle(\"Polca Analysis of the summation of latent orthogonal components\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16677b64a2bfe98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "o1 = widgets.Output()\n",
    "o2 = widgets.Output()\n",
    "\n",
    "\n",
    "with o1:\n",
    "    scores = model_iris.score(X)\n",
    "    sns.displot(scores, kde=True, fill=False, color=\"black\")\n",
    "    plt.title(\"Last component with clean data\")\n",
    "    plt.show()\n",
    "\n",
    "with o2:\n",
    "    scores = model_iris.score(X * (np.random.random(size=X.shape) - 0.5) * 1)\n",
    "    sns.displot(scores, kde=True, fill=False, color=\"black\")\n",
    "    plt.title(\"Last componet with uniform noise in data\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "layout = widgets.Layout(grid_template_columns=\"repeat(2, 500px)\")\n",
    "accordion = widgets.GridBox(children=[o1, o2], layout=layout)\n",
    "display(accordion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf813b50072c8142",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_iris.std_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec75b2242dabfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_iris.mean_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52281ec79aef15d0",
   "metadata": {},
   "source": [
    "## Test Classification with two components on PCA vs POLCA Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84aa81b2994127da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ttest_rel\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, RidgeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caf8a5313ded7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2249f150e68644e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "X_train_pca.shape, X_test_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3dbe4e94fa0a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data using POLCA-Net\n",
    "X_train_polca = model_iris.predict(X_train, np.array([1, 1, 0, 0]))[0][:, :2]\n",
    "#X_train_polca = model_iris.predict(X_trai)[0][:, :pca.n_components]\n",
    "X_test_polca = model_iris.predict(X_test, np.array([1, 1, 0, 0]))[0][:, :2]\n",
    "#X_test_polca = model_iris.predict(X_test)[0][:, :pca.n_components]\n",
    "X_train_polca.shape, X_test_polca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8259fd209f06dfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classifiers\n",
    "classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "    \"Linear SVM\": SVC(kernel=\"linear\", probability=True),\n",
    "    \"Ridge Classifier\": RidgeClassifier(),\n",
    "    \"Perceptron\": Perceptron(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd986e81971100b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate classifiers on both PCA and POLCA-Net transformed datasets\n",
    "results = []\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    # Train on PCA\n",
    "    clf.fit(X_train_pca, y_train)\n",
    "    y_pred_pca = clf.predict(X_test_pca)\n",
    "    accuracy_pca = accuracy_score(y_test, y_pred_pca)\n",
    "    report_pca = classification_report(y_test, y_pred_pca, output_dict=True)\n",
    "\n",
    "    # Train on POLCA-Net\n",
    "    clf.fit(X_train_polca, y_train)\n",
    "    y_pred_polca = clf.predict(X_test_polca)\n",
    "    accuracy_polca = accuracy_score(y_test, y_pred_polca)\n",
    "    report_polca = classification_report(y_test, y_pred_polca, output_dict=True)\n",
    "\n",
    "    # Append results\n",
    "    results.append(\n",
    "        {\n",
    "            \"Classifier\": name,\n",
    "            \"Transformation\": \"PCA\",\n",
    "            \"Accuracy\": accuracy_pca,\n",
    "            \"Precision\": report_pca[\"weighted avg\"][\"precision\"],\n",
    "            \"Recall\": report_pca[\"weighted avg\"][\"recall\"],\n",
    "            \"F1-Score\": report_pca[\"weighted avg\"][\"f1-score\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    results.append(\n",
    "        {\n",
    "            \"Classifier\": name,\n",
    "            \"Transformation\": \"POLCA-Net\",\n",
    "            \"Accuracy\": accuracy_polca,\n",
    "            \"Precision\": report_polca[\"weighted avg\"][\"precision\"],\n",
    "            \"Recall\": report_polca[\"weighted avg\"][\"recall\"],\n",
    "            \"F1-Score\": report_polca[\"weighted avg\"][\"f1-score\"],\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48808a9a50741d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to display the results\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9493a4d4aa7252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical test: Paired t-test for accuracies\n",
    "comparison_metrics = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"]\n",
    "print(f\"\\nPaired t-test results:\")\n",
    "for comparison_metric in comparison_metrics:\n",
    "\n",
    "    print(f\"{comparison_metric}:\")\n",
    "    pca_result = results_df[results_df[\"Transformation\"] == \"PCA\"][comparison_metric]\n",
    "    polca_result = results_df[results_df[\"Transformation\"] == \"POLCA-Net\"][\n",
    "        comparison_metric\n",
    "    ]\n",
    "    t_stat, p_value = ttest_rel(pca_result.values, polca_result.values)\n",
    "    print(f\"\\tt-statistic = {t_stat}, p-value = {p_value}, p-value threshold < {0.05}\")\n",
    "    if p_value < 0.05:\n",
    "        # print(f\"There is a statistically significant difference between the PCA and POLCA-Net transformations\")\n",
    "        ans = \"a\"\n",
    "    else:\n",
    "        ans = \"no\"\n",
    "\n",
    "    print(\n",
    "        f\"\\tThere is {ans} statistically significant difference between the PCA and POLCA-Net transformations.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8430d9d-454e-414b-acc2-ed535ac5aa44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1044b235-4c73-4c6c-939a-f6c3389d0bca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
